{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600620818501",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-45bb594e0ec6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_boston\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 加载数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# 加载数据\n",
    "data=load_boston()\n",
    "# 分割数据\n",
    "train_x, test_x, train_y, test_y = train_test_split(data.data, data.target, test_size=0.25, random_state=33)\n",
    "# 使用AdaBoost回归模型\n",
    "regressor=AdaBoostRegressor()\n",
    "regressor.fit(train_x,train_y)\n",
    "pred_y = regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"房价预测结果 \", pred_y)\n",
    "print(\"均方误差 = \",round(mse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DecisionTreeRegressor' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-513d5ab3abd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 使用决策树回归模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdec_regressor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdec_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用决策树回归模型\n",
    "dec_regressor=DecisionTreeRegressor()\n",
    "dec_regressor.fit(train_x,train_y)\n",
    "pred_y = dec_regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"决策树均方误差 = \",round(mse,2))\n",
    "# 使用KNN回归模型\n",
    "knn_regressor=KNeighborsRegressor()\n",
    "knn_regressor.fit(train_x,train_y)\n",
    "pred_y = knn_regressor.predict(test_x)\n",
    "mse = mean_squared_error(test_y, pred_y)\n",
    "print(\"KNN均方误差 = \",round(mse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "# 设置AdaBoost迭代次数\n",
    "n_estimators=200\n",
    "# 使用\n",
    "X,y=datasets.make_hastie_10_2(n_samples=12000,random_state=1)\n",
    "# 从12000个数据中取前2000行作为测试集，其余作为训练集\n",
    "train_x, train_y = X[2000:],y[2000:]\n",
    "test_x, test_y = X[:2000],y[:2000]\n",
    "# 弱分类器\n",
    "dt_stump = DecisionTreeClassifier(max_depth=1,min_samples_leaf=1)\n",
    "dt_stump.fit(train_x, train_y)\n",
    "dt_stump_err = 1.0-dt_stump.score(test_x, test_y)\n",
    "# 决策树分类器\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(train_x,  train_y)\n",
    "dt_err = 1.0-dt.score(test_x, test_y)\n",
    "# AdaBoost分类器\n",
    "ada = AdaBoostClassifier(base_estimator=dt_stump,n_estimators=n_estimators)\n",
    "ada.fit(train_x,  train_y)\n",
    "# 三个分类器的错误率可视化\n",
    "fig = plt.figure()\n",
    "# 设置plt正确显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot([1,n_estimators],[dt_stump_err]*2, 'k-', label=u'决策树弱分类器 错误率')\n",
    "ax.plot([1,n_estimators],[dt_err]*2,'k--', label=u'决策树模型 错误率')\n",
    "ada_err = np.zeros((n_estimators,))\n",
    "# 遍历每次迭代的结果 i为迭代次数, pred_y为预测结果\n",
    "for i,pred_y in enumerate(ada.staged_predict(test_x)):\n",
    "     # 统计错误率\n",
    "    ada_err[i]=zero_one_loss(pred_y, test_y)\n",
    "# 绘制每次迭代的AdaBoost错误率 \n",
    "ax.plot(np.arange(n_estimators)+1, ada_err, label='AdaBoost Test 错误率', color='orange')\n",
    "ax.set_xlabel('迭代次数')\n",
    "ax.set_ylabel('错误率')\n",
    "leg=ax.legend(loc='upper right',fancybox=True)\n",
    "plt.show()"
   ]
  }
 ]
}